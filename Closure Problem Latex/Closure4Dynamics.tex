\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{geometry}
\geometry{margin=1in}

\title{Addressing the Closure Problem: State Estimation and Neural Approaches for Partially Observable Dynamical Systems}
\author{Matthew G. Galarza}
\date{Last Updated: \today}
% \date{\today}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

A fundamental challenge in the modeling of complex dynamical systems is one of closure where the evolution of the resolved variables depends on unresolved states, processes, and scales that are not directly accessible. This mismatch between the “true” system and its analytical or reduced approximation stems from partial observability, missing or inaccurate physics, and parameter uncertainty. The challenge is ubiqutous, appearing in a variety of diverse fields including turbulence modeling, climate science, molecular dynamics, and biological systems.

\subsection{General Mathematical Formulation}
Consider a general dynamical system with state variables partitioned into resolved (observable) and unresolved (hidden) components:
\begin{equation}
\frac{d}{dt}\begin{bmatrix} \mathbf{u} \\ \mathbf{v} \end{bmatrix} = \begin{bmatrix} f(\mathbf{u}, \mathbf{v}, t) \\ g(\mathbf{u}, \mathbf{v}, t) \end{bmatrix}
\end{equation}
where $\mathbf{u}$ represents resolved/observable states and $\mathbf{v}$ represents unresolved/hidden states. When only $\mathbf{u}$ is observable, the evolution equation becomes:
\begin{equation}
\frac{d\mathbf{u}}{dt} = f(\mathbf{u}, \mathbf{v}, t)
\end{equation}
The closure problem emerges because the right-hand side depends on the unobservable $\mathbf{v}$, requiring a closure model:
\begin{equation}
\frac{d\mathbf{u}}{dt} = f(\mathbf{u}, \mathcal{C}(\mathbf{u}, t), t)
\end{equation}
where $\mathcal{C}(\mathbf{u}, t)$ is the closure approximation that models the effect of unresolved variables.

\subsection{Modern Data-Driven Approaches}

\subsubsection{Neural Closure Models}
Recent advances leverage neural networks to learn closure relationships from data:
\begin{equation}
\mathcal{C}(\mathbf{u}, t) = \mathcal{N}_{\boldsymbol{\theta}}(\mathbf{u}, t) + \int_{-\infty}^{t} \mathcal{K}_{\boldsymbol{\phi}}(\mathbf{u}(s), t-s) ds
\end{equation}
where $\mathcal{N}_{\boldsymbol{\theta}}$ captures Markovian (instantaneous) effects and $\mathcal{K}_{\boldsymbol{\phi}}$ models non-Markovian (memory) effects.

\subsubsection{Physics-Informed Machine Learning}
Hybrid approaches combine physical constraints with data-driven learning:
\begin{itemize}
    \item \textbf{Universal Differential Equations}: Augment known physics with neural network corrections
    \item \textbf{Neural Differential-Algebraic Equations}: Enforce conservation laws through algebraic constraints
    \item \textbf{Operator learning}: Learn mappings between function spaces for closure relationships
\end{itemize}

\subsection{Key Challenges in Closure Modeling}

\begin{enumerate}
    \item \textbf{Structural uncertainty}: The functional form of the closure is often unknown
    \item \textbf{Scale separation}: Unresolved scales may span multiple orders of magnitude
    \item \textbf{Non-Markovian effects}: Hidden states may have long memory effects
    \item \textbf{Generalization}: Closure models must extrapolate to conditions beyond training data
    \item \textbf{Stability}: Inappropriate closures can lead to numerical instabilities or unphysical solutions
    \item \textbf{Interpretability}: Understanding what the closure model has learned remains challenging
\end{enumerate}

\section{Specific Problem Formulation}

\subsection{Application to Electromechanical Systems}
We now apply these closure modeling concepts to a specific challenge in electromechanical systems where complex internal dynamics manifest through limited observable quantities. Our system exemplifies many of the classical closure challenges: multiple unobservable states influencing observable dynamics, cascaded physics across different scales, and regime-switching behavior that complicates traditional modeling approaches.

\subsection{System Description}
We consider a complex electromechanical system governed by an analytical model with six state variables. The system dynamics can be expressed as:
\begin{equation}
\frac{d\mathbf{x}}{dt} = f_{\text{analytical}}(\mathbf{x}, u_{\text{force}}; \boldsymbol{\theta}_{\text{physics}})
\end{equation}
where $\mathbf{x} = [x_1, x_2, x_3, x_4, x_5, V]^T$ represents the full state vector with $V$ being the voltage output, $u_{\text{force}}$ is the input force, and $\boldsymbol{\theta}_{\text{physics}}$ are known physical parameters.

\subsection{Observability Challenge}
The fundamental challenge arises from partial observability:
\begin{itemize}
    \item \textbf{Available measurements}: Input force $u_{\text{force}}(t)$ and output voltage $V(t)$
    \item \textbf{Hidden states}: Five internal states $\{x_1, x_2, x_3, x_4, x_5\}$ that influence system dynamics but are not directly observable
    \item \textbf{Closure problem}: How to accurately model the influence of unobserved states on the observable voltage dynamics
\end{itemize}

This creates a closure problem where the evolution of the observable state depends on hidden states through complex cascaded physics:
\begin{equation}
\frac{dV}{dt} = g(V, \mathbf{x}_{\text{hidden}}, u_{\text{force}})
\end{equation}
where $\mathbf{x}_{\text{hidden}} = [x_1, x_2, x_3, x_4, x_5]^T$ are not available from experimental data.

\subsection{Hybrid Dynamics}
The system exhibits regime-switching behavior when sufficient input force causes electrode collision, introducing discontinuous dynamics:
\begin{equation}
f(\mathbf{x}, u) = 
\begin{cases}
    f_{\text{normal}}(\mathbf{x}, u) & \text{if no collision} \\
    f_{\text{collision}}(\mathbf{x}, u) + F_{\text{contact}} & \text{if collision occurs}
\end{cases}
\end{equation}

\section{Proposed Solution Methods}

\subsection{Neural Differential-Algebraic Equations via Operator Splitting}

Building on recent advances in neural DAEs \cite{koch2024learning}, we propose an operator splitting approach that separates known physics from learned closure terms.

\subsubsection{Mathematical Framework}
The system is reformulated as a semi-explicit DAE:
\begin{align}
\frac{dx}{dt} &= f(\mathbf{x}, \mathbf{y}, u; \boldsymbol{\theta}_f) \\
0 &= g(\mathbf{x}, \mathbf{y}, u)
\end{align}
where $\mathbf{x}$ are differential states, $\mathbf{y}$ are algebraic states representing closure relationships, and $g$ enforces physical constraints.

\subsubsection{Operator Splitting Scheme}
Following the Lie-Trotter splitting methodology:
\begin{align}
\mathbf{y}^{(t+\Delta t)} &= h\left(\mathbf{x}^{(t)}, V^{(t)}, u^{(t)}; \boldsymbol{\theta}_h\right) \tag{Algebraic Update} \\
\mathbf{x}^{(t+\Delta t)} &= \text{ODESolve}\left(f, \{\mathbf{x}^{(t)}, \mathbf{y}^{(t+\Delta t)}, u^{(t)}\}; \boldsymbol{\theta}_f\right) \tag{Differential Update}
\end{align}

The neural surrogate $h: \mathbb{R}^{n_x} \times \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}^{n_y}$ learns the algebraic closure mapping from observable quantities.

\subsection{Universal Differential Equations with Physics Constraints}

An alternative approach combines known analytical models with neural network corrections:
\begin{equation}
\frac{d\mathbf{x}}{dt} = f_{\text{analytical}}(\mathbf{x}, u) + \mathcal{N}_{\boldsymbol{\theta}}(\mathbf{x}, u, t)
\end{equation}
where $\mathcal{N}_{\boldsymbol{\theta}}$ is a neural network that learns the discrepancy between the analytical model and true system dynamics.

\subsubsection{Physics-Informed Loss Function}
Training employs a multi-objective loss:
\begin{equation}
\mathcal{L}(\boldsymbol{\theta}) = \lambda_1 \|\mathbf{V}_{\text{pred}} - \mathbf{V}_{\text{obs}}\|^2 + \lambda_2 \mathcal{L}_{\text{constraints}} + \lambda_3 \|\boldsymbol{\theta}\|^2
\end{equation}
where:
\begin{itemize}
    \item $\mathcal{L}_{\text{constraints}}$ enforces conservation laws and physical constraints
    \item The regularization term prevents overfitting to noise
\end{itemize}

\subsection{Generalized Neural Closure Models}

Following the framework of neural closure models for turbulent systems, we incorporate both Markovian and non-Markovian closure terms:
\begin{equation}
\frac{\partial u}{\partial t} = \mathcal{D}(u) + \mathcal{M}(u; \boldsymbol{\theta}_M) + \int_{-\infty}^{t} \mathcal{K}(u(s), t-s; \boldsymbol{\theta}_{NM}) ds
\end{equation}
where:
\begin{itemize}
    \item $\mathcal{D}(u)$ represents the known low-fidelity model
    \item $\mathcal{M}(u; \boldsymbol{\theta}_M)$ captures instantaneous closure effects
    \item $\mathcal{K}$ models memory effects through time delays
\end{itemize}

\section{Implementation Strategy}

\subsection{Phase 1: Non-Collision Regime}
\begin{enumerate}
    \item \textbf{Data Preprocessing}:
    \begin{itemize}
        \item Filter experimental data to exclude collision events
        \item Normalize states using physics-based bounds
        \item Create delay embeddings for voltage time series
    \end{itemize}
    
    \item \textbf{Model Training}:
    \begin{itemize}
        \item Initialize neural networks with small random weights
        \item Use adaptive learning rates with gradient clipping
        \item Employ early stopping based on validation loss
    \end{itemize}
    
    \item \textbf{Validation}:
    \begin{itemize}
        \item Test extrapolation to unseen operating conditions
        \item Verify conservation law satisfaction
        \item Assess robustness to measurement noise
    \end{itemize}
\end{enumerate}

\subsection{Phase 2: Hybrid Dynamics Extension}
\begin{enumerate}
    \item Implement regime detection based on state constraints
    \item Train separate closure models for each regime
    \item Develop smooth transition mechanisms between regimes
\end{enumerate}

\section{Expected Advantages}

\subsection{Operator Splitting Approach}
\begin{itemize}
    \item \textbf{Interpretability}: Clear separation between known physics and learned corrections
    \item \textbf{Constraint satisfaction}: Algebraic constraints explicitly enforced at each timestep
    \item \textbf{Computational efficiency}: Leverages existing ODE solvers for differential components
\end{itemize}

\subsection{Physics-Informed Learning}
\begin{itemize}
    \item \textbf{Data efficiency}: Requires only observable voltage measurements
    \item \textbf{Generalization}: Physics constraints prevent unphysical extrapolation
    \item \textbf{Noise robustness}: Regularization through physical laws
\end{itemize}

\section{Preliminary Results and Validation}

\subsection{Benchmark Systems}
Initial validation on benchmark problems demonstrates:
\begin{itemize}
    \item Tank-manifold system: Successfully learned unknown area-height profiles with MSE $< 10^{-2}$
    \item Network dynamics: Captured complex feedback mechanisms with 20 dB SNR noise tolerance
    \item Extrapolation capability: Models generalize to unseen parameter regimes
\end{itemize}

\subsection{Challenges and Mitigation Strategies}
\begin{enumerate}
    \item \textbf{Numerical stability}: Addressed through adaptive timestep control and gradient clipping
    \item \textbf{Local minima}: Mitigated using ensemble training with different initializations
    \item \textbf{Overfitting}: Prevented through physics-based regularization and cross-validation
\end{enumerate}

\section{Future Work}

\subsection{Immediate Goals}
\begin{itemize}
    \item Complete implementation of operator splitting framework for the 6-state system
    \item Conduct systematic hyperparameter optimization
    \item Compare performance against baseline methods (pure neural ODE, Kalman filtering)
\end{itemize}

\subsection{Long-term Objectives}
\begin{itemize}
    \item Extend to full hybrid dynamics with collision modeling
    \item Develop theoretical guarantees for closure model convergence
    \item Investigate transfer learning to related electromechanical systems
\end{itemize}

\section{Conclusion}

The proposed hybrid approach combining operator splitting, physics-informed learning, and neural closure models offers a principled framework for addressing the partial observability challenge in complex dynamical systems. By leveraging both analytical knowledge and data-driven learning, this methodology promises improved accuracy, interpretability, and generalization compared to purely black-box approaches.

\begin{thebibliography}{9}

\bibitem{koch2024learning}
Koch, J., Shapiro, M., Sharma, H., Vrabie, D., \& Drgoňa, J. (2024).
Learning Neural Differential Algebraic Equations via Operator Splitting.
\textit{Proceedings of the Conference on Neural Information Processing Systems}.

\bibitem{gupta2021neural}
Gupta, A., \& Lermusiaux, P. F. (2021).
Neural closure models for dynamical systems.
\textit{Proceedings of the Royal Society A}, 477(2252), 20210063.

\bibitem{chen2018neural}
Chen, R. T., Rubanova, Y., Bettencourt, J., \& Duvenaud, D. K. (2018).
Neural ordinary differential equations.
\textit{Advances in neural information processing systems}, 31.

\bibitem{rackauckas2020universal}
Rackauckas, C., Ma, Y., Martensen, J., Warner, C., Zubov, K., Supekar, R., ... \& Edelman, A. (2020).
Universal differential equations for scientific machine learning.
\textit{arXiv preprint arXiv:2001.04385}.

\end{thebibliography}

\end{document}